{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation (F-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "class SharedTaskConstants:\n",
    "    \"\"\"\n",
    "    Use these constants to interface with the data, not with the id2label used\n",
    "    inside the Huggingface models!!\n",
    "    \"\"\"\n",
    "    targets = ['validity', 'novelty']\n",
    "    validity_label_mapping = {\n",
    "        -1: \"not-valid\",\n",
    "        0: \"not-valid\",  # can be excluded since test set does not contain these\n",
    "        1: \"valid\",\n",
    "    }\n",
    "\n",
    "    novelty_label_mapping = {\n",
    "        -1: \"not-novel\",\n",
    "        0: \"not-novel\",  # can be excluded since test set does not contain these\n",
    "        1: \"novel\",\n",
    "    }\n",
    "\n",
    "    validity_id2label = {v: k for k, v in validity_label_mapping.items()}\n",
    "    novelty_id2label = {v: k for k, v in novelty_label_mapping.items()}\n",
    "\n",
    "    local_str_mapping = {\n",
    "        'novel': 1,\n",
    "        'not-novel': 0,\n",
    "        'valid': 1,\n",
    "        'not-valid': 0\n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def val_nov_metric(is_validity: np.ndarray, should_validity: np.ndarray, is_novelty: np.ndarray,\n",
    "                       should_novelty: np.ndarray) -> Dict[str, float]:\n",
    "        ret = dict()\n",
    "\n",
    "        ret_base_help = {\n",
    "            \"true_positive_validity\": np.sum(np.where(\n",
    "                np.all(np.stack([is_validity >= .5, should_validity >= .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"true_positive_novelty\": np.sum(np.where(\n",
    "                np.all(np.stack([is_novelty >= .5, should_novelty >= .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"true_positive_valid_novel\": np.sum(np.where(\n",
    "                np.all(np.stack([is_validity >= .5, is_novelty >= .5,\n",
    "                                 should_validity >= .5, should_novelty >= .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"true_positive_nonvalid_novel\": np.sum(np.where(\n",
    "                np.all(np.stack([is_validity < .5, is_novelty >= .5,\n",
    "                                 should_validity < .5, should_novelty >= .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"true_positive_valid_nonnovel\": np.sum(np.where(\n",
    "                np.all(np.stack([is_validity >= .5, is_novelty < .5,\n",
    "                                 should_validity >= .5, should_novelty < .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"true_positive_nonvalid_nonnovel\": np.sum(np.where(\n",
    "                np.all(np.stack([is_validity < .5, is_novelty < .5,\n",
    "                                 should_validity < .5, should_novelty < .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"classified_positive_validity\": np.sum(np.where(is_validity >= .5, 1, 0)),\n",
    "            \"classified_positive_novelty\": np.sum(np.where(is_novelty >= .5, 1, 0)),\n",
    "            \"classified_positive_valid_novel\": np.sum(np.where(\n",
    "                np.all(np.stack([is_validity >= .5, is_novelty >= .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"classified_positive_nonvalid_novel\": np.sum(np.where(\n",
    "                np.all(np.stack([is_validity < .5, is_novelty >= .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"classified_positive_valid_nonnovel\": np.sum(np.where(\n",
    "                np.all(np.stack([is_validity >= .5, is_novelty < .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"classified_positive_nonvalid_nonnovel\": np.sum(np.where(\n",
    "                np.all(np.stack([is_validity < .5, is_novelty < .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"indeed_positive_validity\": np.sum(np.where(should_validity >= .5, 1, 0)),\n",
    "            \"indeed_positive_novelty\": np.sum(np.where(should_novelty >= .5, 1, 0)),\n",
    "            \"indeed_positive_valid_novel\": np.sum(np.where(\n",
    "                np.all(np.stack([should_validity >= .5, should_novelty >= .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"indeed_positive_nonvalid_novel\": np.sum(np.where(\n",
    "                np.all(np.stack([should_validity < .5, should_novelty >= .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"indeed_positive_valid_nonnovel\": np.sum(np.where(\n",
    "                np.all(np.stack([should_validity >= .5, should_novelty < .5]), axis=0),\n",
    "                1, 0)),\n",
    "            \"indeed_positive_nonvalid_nonnovel\": np.sum(np.where(\n",
    "                np.all(np.stack([should_validity < .5, should_novelty < .5]), axis=0),\n",
    "                1, 0)),\n",
    "        }\n",
    "\n",
    "        ret_help = {\n",
    "            \"precision_validity\": ret_base_help[\"true_positive_validity\"] /\n",
    "                                  max(1, ret_base_help[\"classified_positive_validity\"]),\n",
    "            \"precision_novelty\": ret_base_help[\"true_positive_novelty\"] /\n",
    "                                 max(1, ret_base_help[\"classified_positive_novelty\"]),\n",
    "            \"recall_validity\": ret_base_help[\"true_positive_validity\"] /\n",
    "                               max(1, ret_base_help[\"indeed_positive_validity\"]),\n",
    "            \"recall_novelty\": ret_base_help[\"true_positive_novelty\"] /\n",
    "                              max(1, ret_base_help[\"indeed_positive_novelty\"]),\n",
    "            \"precision_valid_novel\": ret_base_help[\"true_positive_valid_novel\"] /\n",
    "                                     max(1, ret_base_help[\"classified_positive_valid_novel\"]),\n",
    "            \"precision_valid_nonnovel\": ret_base_help[\"true_positive_valid_nonnovel\"] /\n",
    "                                        max(1, ret_base_help[\"classified_positive_valid_nonnovel\"]),\n",
    "            \"precision_nonvalid_novel\": ret_base_help[\"true_positive_nonvalid_novel\"] /\n",
    "                                        max(1, ret_base_help[\"classified_positive_nonvalid_novel\"]),\n",
    "            \"precision_nonvalid_nonnovel\": ret_base_help[\"true_positive_nonvalid_nonnovel\"] /\n",
    "                                           max(1, ret_base_help[\"classified_positive_nonvalid_nonnovel\"]),\n",
    "            \"recall_valid_novel\": ret_base_help[\"true_positive_valid_novel\"] /\n",
    "                                  max(1, ret_base_help[\"indeed_positive_valid_novel\"]),\n",
    "            \"recall_valid_nonnovel\": ret_base_help[\"true_positive_valid_nonnovel\"] /\n",
    "                                     max(1, ret_base_help[\"indeed_positive_valid_nonnovel\"]),\n",
    "            \"recall_nonvalid_novel\": ret_base_help[\"true_positive_nonvalid_novel\"] /\n",
    "                                     max(1, ret_base_help[\"indeed_positive_nonvalid_novel\"]),\n",
    "            \"recall_nonvalid_nonnovel\": ret_base_help[\"true_positive_nonvalid_nonnovel\"] /\n",
    "                                        max(1, ret_base_help[\"indeed_positive_nonvalid_nonnovel\"])\n",
    "        }\n",
    "\n",
    "        ret.update({\n",
    "            \"f1_validity\": 2 * ret_help[\"precision_validity\"] * ret_help[\"recall_validity\"] / max(1e-4, ret_help[\n",
    "                \"precision_validity\"] + ret_help[\"recall_validity\"]),\n",
    "            \"f1_novelty\": 2 * ret_help[\"precision_novelty\"] * ret_help[\"recall_novelty\"] / max(1e-4, ret_help[\n",
    "                \"precision_novelty\"] + ret_help[\"recall_novelty\"]),\n",
    "            \"f1_valid_novel\": 2 * ret_help[\"precision_valid_novel\"] * ret_help[\"recall_valid_novel\"] / max(1e-4,\n",
    "                                                                                                           ret_help[\n",
    "                                                                                                               \"precision_valid_novel\"] +\n",
    "                                                                                                           ret_help[\n",
    "                                                                                                               \"recall_valid_novel\"]),\n",
    "            \"f1_valid_nonnovel\": 2 * ret_help[\"precision_valid_nonnovel\"] * ret_help[\"recall_valid_nonnovel\"] / max(\n",
    "                1e-4, ret_help[\"precision_valid_nonnovel\"] + ret_help[\"recall_valid_nonnovel\"]),\n",
    "            \"f1_nonvalid_novel\": 2 * ret_help[\"precision_nonvalid_novel\"] * ret_help[\"recall_nonvalid_novel\"] / max(\n",
    "                1e-4, ret_help[\"precision_nonvalid_novel\"] + ret_help[\"recall_nonvalid_novel\"]),\n",
    "            \"f1_nonvalid_nonnovel\": 2 * ret_help[\"precision_nonvalid_nonnovel\"] * ret_help[\n",
    "                \"recall_nonvalid_nonnovel\"] / max(1e-4, ret_help[\"precision_nonvalid_nonnovel\"] + ret_help[\n",
    "                \"recall_nonvalid_nonnovel\"])\n",
    "        })\n",
    "\n",
    "        ret.update({\n",
    "            \"f1_macro\": (ret[\"f1_valid_novel\"] + ret[\"f1_valid_nonnovel\"] + ret[\"f1_nonvalid_novel\"] + ret[\n",
    "                \"f1_nonvalid_nonnovel\"]) / 4\n",
    "        })\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(baseline_name: str, y_true: dict, y_pred: dict):\n",
    "    print(f\"==== {baseline_name} ====\")\n",
    "    print(\"Validity\")\n",
    "    results_validity = classification_report(\n",
    "        y_true['validity'],\n",
    "        y_pred['validity'],\n",
    "        target_names=['not-valid', 'valid'],\n",
    "        labels=[0, 1],\n",
    "        zero_division=0\n",
    "    )\n",
    "    print(results_validity)\n",
    "\n",
    "    print(\"Novelty\")\n",
    "    results_novelty = classification_report(\n",
    "        y_true['novelty'],\n",
    "        y_pred['novelty'],\n",
    "        target_names=['not-novel', 'novel'],\n",
    "        labels=[0, 1],\n",
    "        zero_division=0\n",
    "    )\n",
    "    print(results_novelty)\n",
    "\n",
    "    print(\"Combined (organization eval)\")\n",
    "    res = SharedTaskConstants.val_nov_metric(\n",
    "        np.array(y_pred['validity']),\n",
    "        np.array(y_true['validity']),\n",
    "        np.array(y_pred['novelty']),\n",
    "        np.array(y_true['novelty']),\n",
    "    )\n",
    "    print(res['f1_macro'].round(4))\n",
    "    return res['f1_macro'].round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_list(text):\n",
    "    '''\n",
    "    Return tensor string into list\n",
    "    '''\n",
    "    # clean string\n",
    "    clean_str = text.replace('tensor(', '').replace(')', '').strip()\n",
    "    # convert to list\n",
    "    tensor = eval(clean_str, {\"torch\": torch, \"__builtins__\": {}})\n",
    "    return tensor\n",
    "\n",
    "def process_covariate_data(df):\n",
    "    '''\n",
    "    Expanding all tensors in a single cell\n",
    "    Make confidence into ordinal variables\n",
    "    '''\n",
    "    # convert str to tensor (list)\n",
    "    SBERT_premise = df.SBERT_premise.apply(lambda x: str_to_list(x))\n",
    "    SBERT_conclusion = df.SBERT_conclusion.apply(lambda x: str_to_list(x))\n",
    "\n",
    "    # expand the list into individual entries\n",
    "    df_expand1 = SBERT_premise.apply(pd.Series)\n",
    "    df_expand2 = SBERT_conclusion.apply(pd.Series)\n",
    "\n",
    "    # assign a meaningful name\n",
    "    df_expand1.columns = ['pre_emb{}'.format(i+1) for i in range(df_expand1.shape[1])]\n",
    "    df_expand2.columns = ['con_emb{}'.format(i+1) for i in range(df_expand2.shape[1])]\n",
    "\n",
    "    # put everything together\n",
    "    df_final = pd.concat([df.drop(['SBERT_premise', \"SBERT_conclusion\"], axis=1), df_expand1, df_expand2], axis=1)\n",
    "    return df_final\n",
    "\n",
    "def preprocess_input(x, y):\n",
    "    '''\n",
    "    return DataLoader for later input into the model\n",
    "    '''\n",
    "    # pd.dataframe to array\n",
    "    x = np.array(x, dtype=np.float64)\n",
    "    y = np.array(y, dtype=np.float64)\n",
    "    # transform y for nn model\n",
    "    # Transform the data\n",
    "    transformation_dict = {\n",
    "    (1, 1): [1, 0, 0, 0],\n",
    "    (1, 0): [0, 1, 0, 0],\n",
    "    (0, 1): [0, 0, 1, 0],\n",
    "    (0, 0): [0, 0, 0, 1],\n",
    "    }\n",
    "    y = np.array([transformation_dict[tuple(row)] for row in y])\n",
    "    # array to tensor\n",
    "    x_torch = torch.tensor(x)\n",
    "    y_torch = torch.tensor(y)\n",
    "    data = TensorDataset(x_torch, y_torch)\n",
    "\n",
    "    batch_size = 10\n",
    "    loader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../Data/TaskA_train_neural_kg.csv\", index_col=False)\n",
    "test = pd.read_pickle(\"../Data/TaskA_test_neural_kg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.loc[:, [\"SBERT_premise\", \"SBERT_conclusion\", \"SBERT_cosine_sim\", \"Irrelevancy\", \"AveDistance\"]]\n",
    "y_train = train.loc[:, [\"Validity\", \"Novelty\"]]\n",
    "X_test = test.loc[:, [\"SBERT_premise\", \"SBERT_conclusion\", \"SBERT_cosine_sim\", \"Irrelevancy\", \"AveDistance\"]]\n",
    "y_test = test.loc[:, [\"Validity\", \"Novelty\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = process_covariate_data(X_train)\n",
    "# X_test = process_covariate_data(X_test)\n",
    "# y_train.replace(-1, 0, inplace=True)\n",
    "# y_test.replace(-1, 0, inplace=True)\n",
    "\n",
    "X_train = train.loc[:,[\"SBERT_cosine_sim\",'Irrelevancy', 'AveDistance']]\n",
    "y_train = train.loc[:,[\"Validity\",'Novelty']]\n",
    "y_train = y_train.replace(-1, 0)\n",
    "\n",
    "X_test = test.loc[:,[\"SBERT_cosine_sim\",'Irrelevancy', 'AveDistance']]\n",
    "y_test = test.loc[:,[\"Validity\",'Novelty']]\n",
    "y_test = y_test.replace(-1, 0)\n",
    "\n",
    "\n",
    "train_loader = preprocess_input(X_train, y_train)\n",
    "test_loader = preprocess_input(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN under pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.input_dim = 3\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = 4\n",
    "        self.fc1 = nn.Linear(self.input_dim, self.hidden_dim)  # Assuming n input features\n",
    "        self.bn1 = nn.BatchNorm1d(self.hidden_dim)  # Batch normalization layer\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc2 = nn.Linear(self.hidden_dim, self.hidden_dim) \n",
    "        self.bn2 = nn.BatchNorm1d(self.hidden_dim)  # Batch normalization layer\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_label = {\"validity\": list(y_test.Validity), \"novelty\": list(y_test.Novelty)}\n",
    "    test_preds = {\"validity\": [], \"novelty\": []}\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = F.one_hot(predicted, num_classes=4)\n",
    "            # Transform the data\n",
    "            transformation_dict = {\n",
    "            (1, 0, 0, 0): (1, 1), \n",
    "            (0, 1, 0, 0): (1, 0),\n",
    "            (0, 0, 1, 0): (0, 1),\n",
    "            (0, 0, 0, 1): (0, 1)\n",
    "            }\n",
    "            predicted = [transformation_dict[tuple(row.tolist())] for row in predicted]\n",
    "            # Obtain the prediction\n",
    "            for pred in predicted:\n",
    "                test_preds[\"validity\"].append(pred[0])\n",
    "                test_preds[\"novelty\"].append(pred[1]) \n",
    "        return print_results(\"Roberta_based\", test_label, test_preds)\n",
    "\n",
    "def train_model(hyperparameters):\n",
    "    model = SimpleNN(hidden_dim=hyperparameters['hidden_dim'], dropout_rate=hyperparameters[\"dropout_rate\"])\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters['lr'])\n",
    "    \n",
    "\n",
    "    for epoch in range(hyperparameters['epochs']):\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs = inputs.float()\n",
    "            targets = targets.float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    f1 = evaluate_model(model, test_loader)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.45      0.12      0.19       206\n",
      "       valid       0.61      0.90      0.73       314\n",
      "\n",
      "    accuracy                           0.59       520\n",
      "   macro avg       0.53      0.51      0.46       520\n",
      "weighted avg       0.55      0.59      0.51       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.57      0.90      0.70       294\n",
      "       novel       0.46      0.12      0.18       226\n",
      "\n",
      "    accuracy                           0.56       520\n",
      "   macro avg       0.52      0.51      0.44       520\n",
      "weighted avg       0.52      0.56      0.47       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1633\n",
      "{'dropout_rate': 0.2, 'epochs': 10, 'hidden_dim': 2, 'lr': 0.001}\n",
      "0.1633\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.45      0.25      0.32       206\n",
      "       valid       0.62      0.80      0.70       314\n",
      "\n",
      "    accuracy                           0.58       520\n",
      "   macro avg       0.53      0.52      0.51       520\n",
      "weighted avg       0.55      0.58      0.55       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.55      0.77      0.64       294\n",
      "       novel       0.39      0.20      0.26       226\n",
      "\n",
      "    accuracy                           0.52       520\n",
      "   macro avg       0.47      0.48      0.45       520\n",
      "weighted avg       0.48      0.52      0.48       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1744\n",
      "{'dropout_rate': 0.2, 'epochs': 10, 'hidden_dim': 2, 'lr': 0.01}\n",
      "0.1744\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.39      0.41      0.40       206\n",
      "       valid       0.60      0.57      0.58       314\n",
      "\n",
      "    accuracy                           0.51       520\n",
      "   macro avg       0.49      0.49      0.49       520\n",
      "weighted avg       0.51      0.51      0.51       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.54      0.55      0.55       294\n",
      "       novel       0.40      0.38      0.39       226\n",
      "\n",
      "    accuracy                           0.48       520\n",
      "   macro avg       0.47      0.47      0.47       520\n",
      "weighted avg       0.48      0.48      0.48       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1595\n",
      "{'dropout_rate': 0.2, 'epochs': 10, 'hidden_dim': 3, 'lr': 0.001}\n",
      "0.1595\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.41      0.30      0.34       206\n",
      "       valid       0.61      0.72      0.66       314\n",
      "\n",
      "    accuracy                           0.55       520\n",
      "   macro avg       0.51      0.51      0.50       520\n",
      "weighted avg       0.53      0.55      0.54       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.56      0.71      0.63       294\n",
      "       novel       0.43      0.28      0.34       226\n",
      "\n",
      "    accuracy                           0.53       520\n",
      "   macro avg       0.50      0.50      0.49       520\n",
      "weighted avg       0.51      0.53      0.51       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1816\n",
      "{'dropout_rate': 0.2, 'epochs': 10, 'hidden_dim': 3, 'lr': 0.01}\n",
      "0.1816\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.39      0.26      0.31       206\n",
      "       valid       0.60      0.74      0.66       314\n",
      "\n",
      "    accuracy                           0.55       520\n",
      "   macro avg       0.50      0.50      0.49       520\n",
      "weighted avg       0.52      0.55      0.52       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.57      0.75      0.65       294\n",
      "       novel       0.46      0.27      0.34       226\n",
      "\n",
      "    accuracy                           0.54       520\n",
      "   macro avg       0.52      0.51      0.50       520\n",
      "weighted avg       0.52      0.54      0.52       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1814\n",
      "{'dropout_rate': 0.2, 'epochs': 30, 'hidden_dim': 2, 'lr': 0.001}\n",
      "0.1814\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.34      0.17      0.23       206\n",
      "       valid       0.59      0.78      0.67       314\n",
      "\n",
      "    accuracy                           0.54       520\n",
      "   macro avg       0.46      0.48      0.45       520\n",
      "weighted avg       0.49      0.54      0.50       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.57      0.81      0.67       294\n",
      "       novel       0.45      0.20      0.28       226\n",
      "\n",
      "    accuracy                           0.54       520\n",
      "   macro avg       0.51      0.50      0.47       520\n",
      "weighted avg       0.52      0.54      0.50       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1617\n",
      "{'dropout_rate': 0.2, 'epochs': 30, 'hidden_dim': 2, 'lr': 0.01}\n",
      "0.1617\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.34      0.22      0.27       206\n",
      "       valid       0.59      0.72      0.65       314\n",
      "\n",
      "    accuracy                           0.52       520\n",
      "   macro avg       0.46      0.47      0.46       520\n",
      "weighted avg       0.49      0.52      0.50       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.55      0.73      0.63       294\n",
      "       novel       0.39      0.23      0.29       226\n",
      "\n",
      "    accuracy                           0.51       520\n",
      "   macro avg       0.47      0.48      0.46       520\n",
      "weighted avg       0.48      0.51      0.48       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1579\n",
      "{'dropout_rate': 0.2, 'epochs': 30, 'hidden_dim': 3, 'lr': 0.001}\n",
      "0.1579\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.40      0.17      0.24       206\n",
      "       valid       0.61      0.83      0.70       314\n",
      "\n",
      "    accuracy                           0.57       520\n",
      "   macro avg       0.50      0.50      0.47       520\n",
      "weighted avg       0.52      0.57      0.52       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.56      0.83      0.67       294\n",
      "       novel       0.41      0.16      0.23       226\n",
      "\n",
      "    accuracy                           0.54       520\n",
      "   macro avg       0.49      0.49      0.45       520\n",
      "weighted avg       0.50      0.54      0.48       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1669\n",
      "{'dropout_rate': 0.2, 'epochs': 30, 'hidden_dim': 3, 'lr': 0.01}\n",
      "0.1669\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.42      0.29      0.34       206\n",
      "       valid       0.61      0.73      0.67       314\n",
      "\n",
      "    accuracy                           0.56       520\n",
      "   macro avg       0.51      0.51      0.50       520\n",
      "weighted avg       0.53      0.56      0.54       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.57      0.73      0.64       294\n",
      "       novel       0.44      0.28      0.35       226\n",
      "\n",
      "    accuracy                           0.53       520\n",
      "   macro avg       0.51      0.51      0.49       520\n",
      "weighted avg       0.51      0.53      0.51       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1881\n",
      "{'dropout_rate': 0.4, 'epochs': 10, 'hidden_dim': 2, 'lr': 0.001}\n",
      "0.1881\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.42      0.69      0.52       206\n",
      "       valid       0.65      0.38      0.48       314\n",
      "\n",
      "    accuracy                           0.50       520\n",
      "   macro avg       0.54      0.53      0.50       520\n",
      "weighted avg       0.56      0.50      0.50       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.60      0.37      0.45       294\n",
      "       novel       0.45      0.68      0.54       226\n",
      "\n",
      "    accuracy                           0.50       520\n",
      "   macro avg       0.52      0.52      0.50       520\n",
      "weighted avg       0.53      0.50      0.49       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1779\n",
      "{'dropout_rate': 0.4, 'epochs': 10, 'hidden_dim': 2, 'lr': 0.01}\n",
      "0.1779\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.38      0.41      0.39       206\n",
      "       valid       0.59      0.55      0.57       314\n",
      "\n",
      "    accuracy                           0.50       520\n",
      "   macro avg       0.48      0.48      0.48       520\n",
      "weighted avg       0.51      0.50      0.50       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.54      0.54      0.54       294\n",
      "       novel       0.40      0.39      0.39       226\n",
      "\n",
      "    accuracy                           0.47       520\n",
      "   macro avg       0.47      0.47      0.47       520\n",
      "weighted avg       0.47      0.47      0.47       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1584\n",
      "{'dropout_rate': 0.4, 'epochs': 10, 'hidden_dim': 3, 'lr': 0.001}\n",
      "0.1584\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.44      0.37      0.40       206\n",
      "       valid       0.62      0.69      0.65       314\n",
      "\n",
      "    accuracy                           0.56       520\n",
      "   macro avg       0.53      0.53      0.53       520\n",
      "weighted avg       0.55      0.56      0.55       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.57      0.67      0.62       294\n",
      "       novel       0.45      0.35      0.39       226\n",
      "\n",
      "    accuracy                           0.53       520\n",
      "   macro avg       0.51      0.51      0.50       520\n",
      "weighted avg       0.52      0.53      0.52       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1911\n",
      "{'dropout_rate': 0.4, 'epochs': 10, 'hidden_dim': 3, 'lr': 0.01}\n",
      "0.1911\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.29      0.11      0.16       206\n",
      "       valid       0.59      0.82      0.69       314\n",
      "\n",
      "    accuracy                           0.54       520\n",
      "   macro avg       0.44      0.47      0.42       520\n",
      "weighted avg       0.47      0.54      0.48       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.58      0.87      0.70       294\n",
      "       novel       0.53      0.18      0.27       226\n",
      "\n",
      "    accuracy                           0.57       520\n",
      "   macro avg       0.55      0.53      0.48       520\n",
      "weighted avg       0.56      0.57      0.51       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1648\n",
      "{'dropout_rate': 0.4, 'epochs': 30, 'hidden_dim': 2, 'lr': 0.001}\n",
      "0.1648\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.41      0.31      0.35       206\n",
      "       valid       0.61      0.72      0.66       314\n",
      "\n",
      "    accuracy                           0.55       520\n",
      "   macro avg       0.51      0.51      0.51       520\n",
      "weighted avg       0.53      0.55      0.54       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.56      0.70      0.62       294\n",
      "       novel       0.42      0.28      0.34       226\n",
      "\n",
      "    accuracy                           0.52       520\n",
      "   macro avg       0.49      0.49      0.48       520\n",
      "weighted avg       0.50      0.52      0.50       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1773\n",
      "{'dropout_rate': 0.4, 'epochs': 30, 'hidden_dim': 2, 'lr': 0.01}\n",
      "0.1773\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.40      0.26      0.32       206\n",
      "       valid       0.60      0.74      0.66       314\n",
      "\n",
      "    accuracy                           0.55       520\n",
      "   macro avg       0.50      0.50      0.49       520\n",
      "weighted avg       0.52      0.55      0.53       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.57      0.74      0.65       294\n",
      "       novel       0.45      0.27      0.34       226\n",
      "\n",
      "    accuracy                           0.54       520\n",
      "   macro avg       0.51      0.51      0.49       520\n",
      "weighted avg       0.52      0.54      0.51       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1766\n",
      "{'dropout_rate': 0.4, 'epochs': 30, 'hidden_dim': 3, 'lr': 0.001}\n",
      "0.1766\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.45      0.22      0.29       206\n",
      "       valid       0.62      0.82      0.71       314\n",
      "\n",
      "    accuracy                           0.58       520\n",
      "   macro avg       0.53      0.52      0.50       520\n",
      "weighted avg       0.55      0.58      0.54       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.55      0.78      0.64       294\n",
      "       novel       0.36      0.16      0.22       226\n",
      "\n",
      "    accuracy                           0.51       520\n",
      "   macro avg       0.45      0.47      0.43       520\n",
      "weighted avg       0.47      0.51      0.46       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1711\n",
      "{'dropout_rate': 0.4, 'epochs': 30, 'hidden_dim': 3, 'lr': 0.01}\n",
      "0.1711\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.00      0.00      0.00       206\n",
      "       valid       0.60      1.00      0.75       314\n",
      "\n",
      "    accuracy                           0.60       520\n",
      "   macro avg       0.30      0.50      0.38       520\n",
      "weighted avg       0.36      0.60      0.45       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.57      1.00      0.72       294\n",
      "       novel       0.00      0.00      0.00       226\n",
      "\n",
      "    accuracy                           0.57       520\n",
      "   macro avg       0.28      0.50      0.36       520\n",
      "weighted avg       0.32      0.57      0.41       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1307\n",
      "{'dropout_rate': 0.5, 'epochs': 10, 'hidden_dim': 2, 'lr': 0.001}\n",
      "0.1307\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.37      0.48      0.42       206\n",
      "       valid       0.58      0.47      0.52       314\n",
      "\n",
      "    accuracy                           0.47       520\n",
      "   macro avg       0.48      0.47      0.47       520\n",
      "weighted avg       0.50      0.47      0.48       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.55      0.48      0.51       294\n",
      "       novel       0.42      0.50      0.46       226\n",
      "\n",
      "    accuracy                           0.48       520\n",
      "   macro avg       0.49      0.49      0.48       520\n",
      "weighted avg       0.49      0.48      0.49       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1571\n",
      "{'dropout_rate': 0.5, 'epochs': 10, 'hidden_dim': 2, 'lr': 0.01}\n",
      "0.1571\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.40      1.00      0.57       206\n",
      "       valid       0.00      0.00      0.00       314\n",
      "\n",
      "    accuracy                           0.40       520\n",
      "   macro avg       0.20      0.50      0.28       520\n",
      "weighted avg       0.16      0.40      0.22       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.00      0.00      0.00       294\n",
      "       novel       0.43      1.00      0.61       226\n",
      "\n",
      "    accuracy                           0.43       520\n",
      "   macro avg       0.22      0.50      0.30       520\n",
      "weighted avg       0.19      0.43      0.26       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.0779\n",
      "{'dropout_rate': 0.5, 'epochs': 10, 'hidden_dim': 3, 'lr': 0.001}\n",
      "0.0779\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.44      0.32      0.37       206\n",
      "       valid       0.62      0.74      0.67       314\n",
      "\n",
      "    accuracy                           0.57       520\n",
      "   macro avg       0.53      0.53      0.52       520\n",
      "weighted avg       0.55      0.57      0.55       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.56      0.71      0.63       294\n",
      "       novel       0.43      0.28      0.34       226\n",
      "\n",
      "    accuracy                           0.52       520\n",
      "   macro avg       0.49      0.49      0.48       520\n",
      "weighted avg       0.50      0.52      0.50       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1854\n",
      "{'dropout_rate': 0.5, 'epochs': 10, 'hidden_dim': 3, 'lr': 0.01}\n",
      "0.1854\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.30      0.15      0.20       206\n",
      "       valid       0.58      0.78      0.66       314\n",
      "\n",
      "    accuracy                           0.53       520\n",
      "   macro avg       0.44      0.46      0.43       520\n",
      "weighted avg       0.47      0.53      0.48       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.55      0.78      0.64       294\n",
      "       novel       0.36      0.16      0.22       226\n",
      "\n",
      "    accuracy                           0.51       520\n",
      "   macro avg       0.45      0.47      0.43       520\n",
      "weighted avg       0.47      0.51      0.46       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1449\n",
      "{'dropout_rate': 0.5, 'epochs': 30, 'hidden_dim': 2, 'lr': 0.001}\n",
      "0.1449\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.35      0.38      0.36       206\n",
      "       valid       0.56      0.53      0.55       314\n",
      "\n",
      "    accuracy                           0.47       520\n",
      "   macro avg       0.45      0.45      0.45       520\n",
      "weighted avg       0.48      0.47      0.47       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.57      0.57      0.57       294\n",
      "       novel       0.44      0.44      0.44       226\n",
      "\n",
      "    accuracy                           0.51       520\n",
      "   macro avg       0.50      0.50      0.50       520\n",
      "weighted avg       0.51      0.51      0.51       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.159\n",
      "{'dropout_rate': 0.5, 'epochs': 30, 'hidden_dim': 2, 'lr': 0.01}\n",
      "0.159\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.36      0.35      0.36       206\n",
      "       valid       0.58      0.58      0.58       314\n",
      "\n",
      "    accuracy                           0.49       520\n",
      "   macro avg       0.47      0.47      0.47       520\n",
      "weighted avg       0.49      0.49      0.49       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.55      0.59      0.56       294\n",
      "       novel       0.40      0.37      0.39       226\n",
      "\n",
      "    accuracy                           0.49       520\n",
      "   macro avg       0.48      0.48      0.48       520\n",
      "weighted avg       0.48      0.49      0.49       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1564\n",
      "{'dropout_rate': 0.5, 'epochs': 30, 'hidden_dim': 3, 'lr': 0.001}\n",
      "0.1564\n",
      "==== Roberta_based ====\n",
      "Validity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-valid       0.41      0.36      0.39       206\n",
      "       valid       0.61      0.66      0.63       314\n",
      "\n",
      "    accuracy                           0.54       520\n",
      "   macro avg       0.51      0.51      0.51       520\n",
      "weighted avg       0.53      0.54      0.53       520\n",
      "\n",
      "Novelty\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not-novel       0.57      0.65      0.61       294\n",
      "       novel       0.44      0.35      0.39       226\n",
      "\n",
      "    accuracy                           0.52       520\n",
      "   macro avg       0.50      0.50      0.50       520\n",
      "weighted avg       0.51      0.52      0.51       520\n",
      "\n",
      "Combined (organization eval)\n",
      "0.1788\n",
      "{'dropout_rate': 0.5, 'epochs': 30, 'hidden_dim': 3, 'lr': 0.01}\n",
      "0.1788\n",
      "Best f1: 0.1911\n",
      "Best Hyperparameters: {'dropout_rate': 0.4, 'epochs': 10, 'hidden_dim': 3, 'lr': 0.01}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_dim': [2, 3],\n",
    "    'lr': [0.001, 0.01],\n",
    "    'epochs': [10, 30],\n",
    "    'dropout_rate': [0.2, 0.4, 0.5]\n",
    "}\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "\n",
    "for params in grid:\n",
    "    f1 = train_model(params)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = params\n",
    "    print(params)\n",
    "    print(f1)\n",
    "print(f\"Best f1: {best_f1}\")\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
